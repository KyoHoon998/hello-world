{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyoHoon998/hello-world/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aToQOvUDDfUj",
        "colab_type": "code",
        "outputId": "bbdd1a5a-20e8-4ef9-e5ae-f6bb798efa81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-13 11:56:22--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  openssl            conda-forge::openssl-1.1.1d-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_3\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2019.11.~ --> pkgs/main::ca-certificates-2019.10.16-0\n",
            "  certifi            conda-forge::certifi-2019.11.28-py37_0 --> pkgs/main::certifi-2019.9.11-py37_0\n",
            "  conda                     conda-forge::conda-4.8.0-py37_0 --> pkgs/main::conda-4.7.12-py37_0\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m23.623s\n",
            "user\t0m31.378s\n",
            "sys\t0m5.204s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m6.252s\n",
            "user\t0m5.495s\n",
            "sys\t0m0.778s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVoXIjacDw4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0YMIOqVESRN",
        "colab_type": "code",
        "outputId": "e2a7a155-01d7-4111-8814-ef1ca3918fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, Descriptors\n",
        "\n",
        "try:\n",
        "\n",
        "    %tensorflow_version 1.x  # %tensorflow_version only exists in Colab\n",
        "\n",
        "except Exception:\n",
        "\n",
        "    pass\n",
        "\n",
        "import tensorflow"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x  # %tensorflow_version only exists in Colab`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VRuyXlFRGCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smifile = \"GDBChEMBL.smi\"\n",
        "data = pd.read_csv(smifile, delimiter = \"\\t\", names = [\"smiles\",\"No\",\"Int\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XeKAkjsMvBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "smiles_train, smiles_test = train_test_split(data[\"smiles\"], random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6EDc-uPM7sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charset = set(\"\".join(list(data.smiles))+\"!E\")\n",
        "char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
        "int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
        "embed = max([len(smile) for smile in data.smiles]) + 5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlN_OQvWRW4I",
        "colab_type": "code",
        "outputId": "4fbacba6-acd5-42bc-e4fb-d2148159364a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "def vectorize(smiles):\n",
        "        one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
        "        for i,smile in enumerate(smiles):\n",
        "            #encode the startchar\n",
        "            one_hot[i,0,char_to_int[\"!\"]] = 1\n",
        "            #encode the rest of the chars\n",
        "            for j,c in enumerate(smile):\n",
        "                one_hot[i,j+1,char_to_int[c]] = 1\n",
        "            #Encode endchar\n",
        "            one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
        "        #Return two, one for input and the other for output\n",
        "        return one_hot[:,0:-1,:], one_hot[:,1:,:]\n",
        "X_train, Y_train = vectorize(smiles_train.values)\n",
        "X_test,Y_test = vectorize(smiles_test.values)\n",
        "plt.matshow(X_train[0].T)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f51218652e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAECCAYAAACyvq3uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqtjMGZIRxbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 564.923x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOp4327CR6Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "input_shape = X_train.shape[1:]\n",
        "output_dim = Y_train.shape[-1]\n",
        "latent_dim = 64\n",
        "lstm_dim = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OsjsCFdSCVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unroll = False\n",
        "encoder_inputs = Input(shape=input_shape)\n",
        "encoder = LSTM(lstm_dim, return_state=True,\n",
        "                unroll=unroll)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = Concatenate(axis=-1)([state_h, state_c])\n",
        "neck = Dense(latent_dim, activation=\"relu\")\n",
        "neck_outputs = neck(states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqcau5MSNxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_h = Dense(lstm_dim, activation=\"relu\")\n",
        "decode_c = Dense(lstm_dim, activation=\"relu\")\n",
        "state_h_decoded =  decode_h(neck_outputs)\n",
        "state_c_decoded =  decode_c(neck_outputs)\n",
        "encoder_states = [state_h_decoded, state_c_decoded]\n",
        "decoder_inputs = Input(shape=input_shape)\n",
        "decoder_lstm = LSTM(lstm_dim,\n",
        "                    return_sequences=True,\n",
        "                    unroll=unroll\n",
        "                   )\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(output_dim, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#Define the model, that inputs the training vector for two places, and predicts one character ahead of the input\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6PM_4HWSP-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import History, ReduceLROnPlateau\n",
        "h = History()\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, min_delta=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjRRj2ooSVnx",
        "colab_type": "code",
        "outputId": "4f3857e3-2f20-4eb8-9b93-8121db75e5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "opt=Adam(lr=0.005) #Default 0.001\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
        "model.fit([X_train,X_train],Y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=256,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[h, rlr],\n",
        "                    validation_data=[[X_test,X_test],Y_test ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 178179 samples, validate on 59394 samples\n",
            "Epoch 1/10\n",
            "111104/178179 [=================>............] - ETA: 34s - loss: 0.6075"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd9t7i8JSaAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(h.history[\"loss\"], label=\"Loss\")\n",
        "plt.plot(h.history[\"val_loss\"], label=\"Val_Loss\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5lXDb3_2YEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    v = model.predict([X_test[i:i+1], X_test[i:i+1]]) #Can't be done as output not necessarely 1\n",
        "    idxs = np.argmax(v, axis=2)\n",
        "    pred=  \"\".join([int_to_char[h] for h in idxs[0]])[:-1]\n",
        "    idxs2 = np.argmax(X_test[i:i+1], axis=2)\n",
        "    true =  \"\".join([int_to_char[k] for k in idxs2[0]])[1:]\n",
        "    if true != pred:\n",
        "        print(true, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-TBDcGK3nZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smiles_to_latent_model = Model(encoder_inputs, neck_outputs)\n",
        "smiles_to_latent_model.save(\"Blog_simple_smi2lat.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T03srvOAjLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_input = Input(shape=(latent_dim,))\n",
        "#reuse_layers\n",
        "state_h_decoded_2 =  decode_h(latent_input)\n",
        "state_c_decoded_2 =  decode_c(latent_input)\n",
        "latent_to_states_model = Model(latent_input, [state_h_decoded_2, state_c_decoded_2])\n",
        "latent_to_states_model.save(\"Blog_simple_lat2state.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIwFJVdhAku4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inf_decoder_inputs = Input(batch_shape=(1, 1, input_shape[1]))\n",
        "inf_decoder_lstm = LSTM(lstm_dim,\n",
        "                    return_sequences=True,\n",
        "                    unroll=unroll,\n",
        "                    stateful=True\n",
        "                   )\n",
        "inf_decoder_outputs = inf_decoder_lstm(inf_decoder_inputs)\n",
        "inf_decoder_dense = Dense(output_dim, activation='softmax')\n",
        "inf_decoder_outputs = inf_decoder_dense(inf_decoder_outputs)\n",
        "sample_model = Model(inf_decoder_inputs, inf_decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgvq6drEAmSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,3):\n",
        "    sample_model.layers[i].set_weights(model.layers[i+6].get_weights())\n",
        "sample_model.save(\"Blog_simple_samplemodel.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch2jIak4Anek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVotZG0vAo_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_latent = smiles_to_latent_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZp9f6lDAric",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "molno = 5\n",
        "latent_mol = smiles_to_latent_model.predict(X_test[molno:molno+1])\n",
        "sorti = np.argsort(np.sum(np.abs(x_latent - latent_mol), axis=1))\n",
        "print (sorti[0:10])\n",
        "print (smiles_test.iloc[sorti[0:8]])\n",
        "Draw.MolsToImage(smiles_test.iloc[sorti[0:8]].apply(Chem.MolFromSmiles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnjJKQzQAy4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Draw.MolsToImage(smiles_test.iloc[sorti[-8:]].apply(Chem.MolFromSmiles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5wPzp6-A7xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logp = smiles_test.apply(Chem.MolFromSmiles).apply(Descriptors.MolLogP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeILjlXxBA-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "red = pca.fit_transform(x_latent)\n",
        "plt.figure()\n",
        "plt.scatter(red[:,0], red[:,1],marker='.', c= logp)\n",
        "print(pca.explained_variance_ratio_, np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBoggzhyBCsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "molwt = smiles_test.apply(Chem.MolFromSmiles).apply(Descriptors.MolMR)\n",
        "plt.figure()\n",
        "plt.scatter(red[:,0], red[:,1],marker='.', c= molwt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDnOG6TwBG-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model LogP?\n",
        "x_train_latent = smiles_to_latent_model.predict(X_train)\n",
        "logp_train = smiles_train.apply(Chem.MolFromSmiles).apply(Descriptors.MolLogP)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN38Wx0HBKt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "logp_model = Sequential()\n",
        "logp_model.add(Dense(128, input_shape=(latent_dim,), activation=\"relu\"))\n",
        "logp_model.add(Dense(128, activation=\"relu\"))\n",
        "logp_model.add(Dense(1))\n",
        "logp_model.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSsU-EtyBNg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, min_delta=1e-5)\n",
        "logp_model.fit(x_train_latent, logp_train, batch_size=128, epochs=10, callbacks = [rlr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hZ61iwmBTxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logp_pred_train = logp_model.predict(x_train_latent)\n",
        "logp_pred_test = logp_model.predict(x_latent)\n",
        "plt.scatter(logp, logp_pred_test, label=\"Test\")\n",
        "plt.scatter(logp_train, logp_pred_train, label=\"Train\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv7Aker-CMiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def latent_to_smiles(latent):\n",
        "    #decode states and set Reset the LSTM cells with them\n",
        "    states = latent_to_states_model.predict(latent)\n",
        "    sample_model.layers[1].reset_states(states=[states[0],states[1]])\n",
        "    #Prepare the input char\n",
        "    startidx = char_to_int[\"!\"]\n",
        "    samplevec = np.zeros((1,1,24))\n",
        "    samplevec[0,0,startidx] = 1\n",
        "    smiles = \"\"\n",
        "    #Loop and predict next char\n",
        "    for i in range(28):\n",
        "        o = sample_model.predict(samplevec)\n",
        "        sampleidx = np.argmax(o)\n",
        "        samplechar = int_to_char[sampleidx]\n",
        "        if samplechar != \"E\":\n",
        "            smiles = smiles + int_to_char[sampleidx]\n",
        "            samplevec = np.zeros((1,1,24))\n",
        "            samplevec[0,0,sampleidx] = 1\n",
        "        else:\n",
        "            break\n",
        "    return smiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmtNPCV3CPU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smiles = latent_to_smiles(x_latent[0:1])\n",
        "print (smiles)\n",
        "print (smiles_test.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwxUQanJCSqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong = 0\n",
        "for i in range(1000):\n",
        "    smiles = latent_to_smiles(x_latent[i:i+1])\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        pass\n",
        "    else:\n",
        "        print (smiles)\n",
        "        wrong = wrong + 1\n",
        "print (\"%0.1F percent wrongly formatted smiles\"%(wrong/float(1000)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAv0IoA6Go_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}